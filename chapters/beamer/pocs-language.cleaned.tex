%% Add spreading of phonemes around the world

%% Add \cite{ferrericancho2003a}

%% Add Heap's law

%% http://en.wikipedia.org/wiki/Heaps'_law

%% Linyuan Lue, Zi-Ke Zhang and Tao Zhou, Zipf's law leads to heaps' law: analyzing their relation in finite-size systems, PLoS ONE 5, e14139, 2010 [html] [doi]


%% add a section on the remnants of other languages
%% the massive impacts of some

%% tuesday, wednesday, thursday

%% other: minutes, seconds, degrees: ancient and universal
%% ways of measuring 


%% add paper showing languages of different cadences 
%% have the same amount of information
%% http://www.time.com/time/health/article/0,8599,2091477,00.html?xid=fblike
%% http://persquaremile.com/2011/12/21/which-reads-faster-chinese-or-english/


%% Add Petersen 2011a

%% Add Culturomics

%% Piantadosi

%% gell-mann2011a

%% spreading as a function of phoneme diversity
%% new zealand dude


%% lieberman2007a
\section{Irregular\ verbs}

  \textbf{Irregular verbs}

  \textbf{Cleaning up English:}
    \alert{``Quantifying the evolutionary dynamics of language''}\cite{lieberman2007a}\\
    Lieberman et al., Nature, Vol 449, 713-716, 2007.
  

      
    \includegraphics[width=\textwidth]{NatureEvolutionofLanguageCover.pdf}
    
    
      
       
        Exploration of how verbs with irregular 
        conjugation gradually become regular over time.
       
        Comparison of verb behavior in Old, Middle, and Modern English.
      
    
  

  \textbf{Irregular verbs}


  
    \includegraphics[width=0.9\textwidth]{lieberman2007a_fig1a}

    
     Universal tendency towards regular conjugation
     Rare verbs tend to be regular in the first place
    
  


  \textbf{Irregular verbs}

  
  \includegraphics[width=\textwidth]{lieberman2007a_fig1b}

  
  
    Rates are relative.
  
    The \alertb{more common} a verb is, the \alertb{more resilient}
    it is to change.
  
  


\begin{frame}[plain]
  \textbf{Irregular verbs}

  
    \includegraphics[width=1.2\textwidth]{lieberman2007a_tab1}

    
     \alert{Red} = regularized
     Estimates of half-life for regularization ($\propto f^{1/2}$)
    
  


  \textbf{Irregular verbs}

  
  \includegraphics[width=\textwidth]{lieberman2007a_fig2a}

  
   
    `Wed' is next to go.
   
    -ed is the winning rule...
  
    But `snuck' is 
    \wordwikilink{http://books.google.com/ngrams/graph?content=snuck\%2Csneaked\&year_start=1800\&year_end=2000\&corpus=0\&smoothing=3}{sneaking up on sneaked.}\cite{michel2010a}
  
  


%% %%   \textbf{Irregular verbs}
%% 
%%   
%%   \includegraphics[width=\textwidth]{lieberman2007a_fig2b}
%% 
%%   
%%    Regularization rate $\propto$ word frequency$^{-1/2}$
%%    Half life $\propto$ word frequency$^{1/2}$
%%   
%%   
%% 
%% 
  \textbf{Irregular verbs}

  
  \includegraphics[width=.95\textwidth]{lieberman2007a_fig3}

  
   Projecting back in time to proto-Zipf story of many tools.
  
  


\section{Word\ lifespans}

\section{Meanings}

  \textbf{Word meanings}

  \textbf{Preliminary findings on word frequency and number of meanings}
    
     
      Corpus: 10,000 most frequent words from Project Gutenberg
     
      \# meanings for each word estimated using \wordwikilink{http://www.dictionary.com}{dictionary.com}
     
      Friends: perl, regular expressions, wget.
    
  


  \textbf{Word meanings}

  
    \begin{tabular}{ll}
      \textbf{A.} & 
      \textbf{B.} \\
      \includegraphics[width=0.47\textwidth]{figwordfreq01_noname.pdf} & 
      \includegraphics[width=0.49\textwidth]{figwordmeaning03c_noname.pdf}
      %%          \includegraphics[width=0.49\textwidth]{figwordmeaning03b_noname.pdf}\\
    \end{tabular}

    \textbf{A.} 
    Word frequency versus rank, 
    slope $\alpha \sim -1.2$ corresponds to
    to a frequency distribution with $\gamma \sim 1.8$.\\
    \textbf{B.} 
    Relationship between average number of meanings and 
    average frequency (bins are by rank, with
    each circle representing 500 words).  Slope of 1/3 lower than
    Zipf's 1/2\cite{zipf1949a}.
  



  \textbf{Word meanings}

  
    \begin{tabular}{ll}
      \textbf{A.} & 
      \textbf{B.} \\
      \includegraphics[width=0.49\textwidth]{figwordmeaning02_noname.pdf} &
      \includegraphics[width=0.46\textwidth]{figwordmeaning03_noname.pdf} \\
    \end{tabular}
    
     Meaning number as a function of word rank.
     The three exponents combine within error:
      $ 1.2 \times 1/3 = 0.4 \simeq 0.45.$
    
  



  \textbf{Word meanings}

  
    \begin{tabular}{ll}
      \textbf{A.} & 
      \textbf{B.} \\
      \includegraphics[width=0.49\textwidth]{figwordmeaning26b_noname.pdf} & 
      \includegraphics[width=0.49\textwidth]{figwordmeaning25b_noname.pdf} \\
    \end{tabular}

    
     
      Scaling collapse for meaning number distribution
     
      Each curve corresponds to approximately 500 words
      group according to rank (1--500, 501--1000, ...).
      
      With normalization
      $$
      P(n_m) = f^{-1/3}
      G \left( f^{-1/3} n_m \right).
      $$
    
  



  \textbf{Word meanings}

  \textbf{Further work:}
    
     Check these scalings again
     Explore alternate data sources
     Think about
      why meaning number might scale with frequency.
     May be an information theoretic story.
     If we add context, we may be able to
      use a modified version of Simon's approach\cite{simon1955a}
    
      The city story here would be that there may
      be many cities and towns with the same
      name (e.g., Springfield) with an uneven distribution in populations.
    
  



