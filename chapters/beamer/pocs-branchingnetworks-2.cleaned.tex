\insertvideo{FnroL1_-l2c}{}{}{Piracy and river networks}

\section{Horton\ \texorpdfstring{$\Leftrightarrow$}{is\ equivalent\ to}\ Tokunaga}

\begin{frame}[label=]
  \textbf{Can Horton and Tokunaga be happy?}

  \textbf{Horton and Tokunaga seem different:}
    
       In terms of network achitecture, 
        Horton's laws appear to contain less
        detailed information than Tokunaga's law.
       Oddly, Horton's laws have \alert{four} parameters
        and Tokunaga has \alert{two} parameters.
       $R_n$, $R_a$, $R_\msl$, and $R_\okell$ \alert{versus} $T_1$ and $R_T$.
        One simple redundancy: $R_\msl = R_\okell$.\\
        \insertassignmentquestion{02}{2}{3}
       To make a connection, clearest approach
        is to start with Tokunaga's law...
       Known result: Tokunaga $\rightarrow$ Horton\cite{tokunaga1966a,tokunaga1978a,tokunaga1984a,peckham1995a,dodds1999a}
    
  


\begin{frame}[label=]
  \textbf{Let us make them happy}

  \alert{We need one more ingredient:}

  \textbf{Space-fillingness}
    
     A network is \alert{space-filling}
      if the average distance between adjacent streams
      is roughly constant.
     Reasonable for river and cardiovascular networks
     For river networks:\\
      \alert{Drainage density $\rhodd$} = inverse of typical distance between
      channels in a landscape.
     In terms of basin characteristics:
      $$
      \rhodd \simeq \frac{\sum \mbox{stream segment lengths}}{\mbox{basin area}}
      {= \frac{\sum_{\om=1}^{\Om} n_\om \bar{\okell}_\om} { a_\Om}}
      $$
    
  


\begin{frame}[label=]
  \textbf{More with the happy-making thing}

  \textbf{Start with Tokunaga's law: $T_k = T_1 R_T^{k-1}$}
    
     
      Start looking for Horton's stream number law: \alert{$n_{\om}/n_{\om+1} = R_n$}.
    
      Estimate $n_\om$, the number of streams of order $\om$ in terms 
      of other $n_{\om'}$, $\om'>\om$.
     
      Observe that each stream of order $\om$ terminates by either:
              
                  
          
          \includegraphics[width=\textwidth]{figstream_gen01_ok}
                          
          
          \includegraphics[width=\textwidth]{figstream_abs01_ok}
                
        
         Running into another stream of order $\om$ and 
          generating a stream of order $\om+1$...
          {
            
              \alert{$2n_{\om+1}$ streams of order $\om$ do this}
            
          }
         Running into and being absorbed by a stream
          of higher order $\om'>\om$...
          {
            
             \alert{$n_{\om'} T_{\om'-\om}$ streams of order $\om$ do this}
            
          }
        
          
  


\begin{frame}[label=]
  \textbf{More with the happy-making thing}

  \textbf{Putting things together:}
    
    
      $$
      n_\om
      =
      \underbrace{\alert{2}n_{\om+1}}_{\textnormal{generation}}
      +
      {
      \sum_{\om'=\om+1}^{\Om}
      \underbrace{\alert{T_{\om'-\om}} n_{\om'}}_{\textnormal{absorption}}
      }
      $$
    
      Use Tokunaga's law and manipulate expression
      to find Horton's law for stream numbers follows
      and hence obtain $R_n$.
    
      \insertassignmentquestion{02}{2}{4}
    
      Solution:
      $$
      R_n
      =
      \frac{
      (2+R_T+T_1)
      \pm 
      \sqrt{
        (2+R_T+T_1)^2-8R_T
        }
      }
      {2}
      $$
      (The larger value is the one we want.)
    
  



\begin{frame}[label=]
  \textbf{Finding other Horton ratios}

  \textbf{Connect Tokunaga to $R_\okell$}
    
     
      Now use uniform drainage density $\rhodd$.
     
      Assume side streams are roughly separated
      by distance $1/\rhodd$.
     For an order $\om$ \alert{stream segment},
      expected length is 
      $$
      \bar{\okell}_\om
      \simeq
      \rhodd^{-1}
      \left(
        1 + \sum_{k=1}^{\om-1} T_k
      \right)
      $$
     Substitute in Tokunaga's law $T_k = T_1 R_T^{k-1}$:
      $$
      \bar{\okell}_\om
      \simeq
      \rhodd^{-1}
      \left(
        1 + T_1 \sum_{k=1}^{\om-1} R_T^{\ k-1}
      \right)
      {
      \propto
      R_T^{\ \om}
      }
      $$
    
  


\begin{frame}[label=]
  \textbf{Horton and Tokunaga are happy}

  \textbf{Altogether then:}
  
   
      $$ \Rightarrow \bar{\okell}_\om/\bar{\okell}_{\om-1} = R_T
      {
        \Rightarrow \alert{R_\okell = R_T} 
      }
      $$
    
      Recall $R_\msl = R_\okell$ so 
      $$ 
      \alert{\boxed{R_\msl = R_\okell =  R_T}}
      $$
    
      And from before:
      $$
      \alert{\boxed{
      R_n
      =
      \frac{
      (2+R_T+T_1)
      +
      \sqrt{
        (2+R_T+T_1)^2-8R_T
        }
      }
      {2}
    }}
      $$
  
  



\begin{frame}[label=]
  \textbf{Horton and Tokunaga are happy}

  \textbf{Some observations:}
    
    
      $R_n$ and $R_\msl$ depend on $T_1$ and $R_T$.
    
      Seems that $R_a$ must as well...
     Suggests Horton's laws must contain some redundancy
     We'll in fact see that $R_a = R_n$.
     Also: Both Tokunaga's law and Horton's laws
      can be generalized to relationships between
      non-trivial statistical distributions.\cite{dodds2001b,dodds2001c}
    
  


\begin{frame}[label=]
  \textbf{Horton and Tokunaga are happy}
  
  \textbf{The other way round}
    
     Note: We can invert the expresssions
      for $R_n$ and $R_\msl$ to find Tokunaga's
      parameters in terms of Horton's parameters.
     
      $$
      R_T = R_\msl,
      $$
    
      $$
      T_1  =  R_n - R_\msl - 2 + 2R_\msl/R_n.
      $$
     
      Suggests we should be able to argue that Horton's laws
      imply Tokunaga's laws (if drainage density is uniform)...
    
  


\begin{frame}[label=]
  \textbf{Horton and Tokunaga are friends}

  \textbf{From Horton to Tokunaga\cite{dodds1999a}}
          
      \includegraphics[width=\textwidth]{hort2tok_abc_PRE_ok}
      
      
       Assume Horton's laws hold for number and length
       Start with picture showing an order $\om$ stream
        and order $\om-1$ generating and side streams.
       Scale up by a factor of $R_\msl$, orders increment
        to $\om+1$ and $\om$.
       Maintain drainage density by adding new order $\om-1$ streams
      
          
  


\begin{frame}[label=]
  \textbf{Horton and Tokunaga are friends}

  \textbf{\ldots and in detail:}
    
     Must retain same drainage density.
     Add an extra $(R_\msl-1)$ first order streams
      for each original tributary.
     Since by definition, an order $\om+1$ stream segment
      has $T_{\om}$ order 1 side streams, we have: 
      {
        $$
        T_{k} = (R_\msl-1)
        \left( 
          1 + 
          \sum_{i=1}^{k-1} T_{i}  
        \right).
        $$
      }
    
      For large $\om$, Tokunaga's law is the solution---let's check...
    

  


\begin{frame}[label=]
  \textbf{Horton and Tokunaga are friends}

  \textbf{Just checking:}
    
     Substitute Tokunaga's law $T_i=T_1 R_T^{\ i-1} = T_1 R_\msl^{\ i-1}$ into
      $$
      T_{k} = (R_\msl-1)
      \left(
        1 +
        \sum_{i=1}^{k-1} T_{i}  
      \right)
      $$
    
        $$ 
        T_{k} 
        = 
        (R_\msl-1)
        \left(
          1 + 
          \sum_{i=1}^{k-1} 
          T_1 R_\msl^{\ i-1}
        \right) 
        $$
        { 
          $$ 
          = (R_\msl-1) 
          \left( 1 + 
            T_1\frac{R_\msl^{\ k-1}-1}{R_\msl - 1} 
          \right) 
          $$
        }
        $$ 
        {
          \simeq 
          (R_\msl-1) T_1 \frac{R_\msl^{\ k-1}}{R_\msl - 1} 
        }
        { 
          = T_1 R_\msl^{k-1}  \quad \mbox{... yep.}
        }
        $$
    
  
  

%%% NOTE: I guess with more work we can derive T_1 from R_n and R_l

\section{Reducing\ Horton}

\begin{frame}[label=]
  \textbf{Horton's laws of area and number:}

  
    \begin{center}
      \includegraphics[width=.3\textwidth]{fignalomega_mispi10} 
      \includegraphics[width=.3\textwidth]{fignalomega_nile} 
      \includegraphics[width=.3\textwidth]{fignalomega_amazon} \\
      \includegraphics[width=.3\textwidth]{fignflipaomega_mispi10} 
      \includegraphics[width=.3\textwidth]{fignflipaomega_nile} 
      \includegraphics[width=.3\textwidth]{fignflipaomega_amazon} 
    \end{center}
    
     
       In bottom plots, stream number graph has been flipped vertically.
     
      Highly suggestive that $R_n \equiv R_a$...
    
  


\begin{frame}[label=]
  \textbf{Measuring Horton ratios is tricky:}
  
  
   How robust are our estimates of ratios?
   Rule of thumb: discard data for two smallest
    and two largest orders.
  


\begin{frame}[label=]
  \textbf{Mississippi:}

  \rowcolors[]{1}{blue!20}{blue!10} 
  \begin{tabular}{cccccc}
    $\omega$ range & $R_n$ & $R_a$ & $R_\msl$ & $R_{\okell}$ & $R_a/R_n$ \\
    $[2,3]$ & 5.27 & 5.26 & 2.48 & 2.30 & 1.00 \\
    $[2,5]$ & 4.86 & 4.96 & 2.42 & 2.31 & 1.02 \\
    $[2,7]$ & 4.77 & 4.88 & 2.40 & 2.31 & 1.02 \\
    $[3,4]$ & 4.72 & 4.91 & 2.41 & 2.34 & 1.04 \\
    $[3,6]$ & 4.70 & 4.83 & 2.40 & 2.35 & 1.03 \\
    $[3,8]$ & 4.60 & 4.79 & 2.38 & 2.34 & 1.04 \\
    $[4,6]$ & 4.69 & 4.81 & 2.40 & 2.36 & 1.02 \\
    $[4,8]$ & 4.57 & 4.77 & 2.38 & 2.34 & 1.05 \\
    $[5,7]$ & 4.68 & 4.83 & 2.36 & 2.29 & 1.03 \\
    $[6,7]$ & 4.63 & 4.76 & 2.30 & 2.16 & 1.03 \\
    $[7,8]$ & 4.16 & 4.67 & 2.41 & 2.56 & 1.12 \\
    mean $\mu$ & 4.69 & 4.85 & 2.40 & 2.33 & 1.04 \\
    std dev $\sigma$ & 0.21 &  0.13 & 0.04 & 0.07 & 0.03 \\
    $\sigma/\mu$ & 0.045 &  0.027 & 0.015 & 0.031 & 0.024 \\
  \end{tabular}

\begin{frame}[label=]
   \textbf{Amazon:}

  \rowcolors[]{1}{blue!20}{blue!10} 
   \begin{tabular}{cccccc}
     $\omega$ range & $R_n$ & $R_a$ & $R_\msl$ & $R_{\okell}$ & $R_a/R_n$ \\
     $[2,3]$ & 4.78 & 4.71 & 2.47 & 2.08 & 0.99 \\
     $[2,5]$ & 4.55 & 4.58 & 2.32 & 2.12 & 1.01 \\
     $[2,7]$ & 4.42 & 4.53 & 2.24 & 2.10 & 1.02 \\
     $[3,5]$ & 4.45 & 4.52 & 2.26 & 2.14 & 1.01 \\
     $[3,7]$ & 4.35 & 4.49 & 2.20 & 2.10 & 1.03 \\
     $[4,6]$ & 4.38 & 4.54 & 2.22 & 2.18 & 1.03 \\
     $[5,6]$ & 4.38 & 4.62 & 2.22 & 2.21 & 1.06 \\
     $[6,7]$ & 4.08 & 4.27 & 2.05 & 1.83 & 1.05 \\
     mean $\mu$ & 4.42 & 4.53 & 2.25 & 2.10 & 1.02 \\
     std dev $\sigma$ & 0.17 &  0.10 & 0.10 & 0.09 & 0.02 \\
     $\sigma/\mu$ & 0.038 &  0.023 & 0.045 & 0.042 & 0.019 \\
   \end{tabular}


\begin{frame}[label=]
  \textbf{Reducing Horton's laws:}
  
  \textbf{Rough first effort to show $R_n \equiv R_a$:}
    
     
      $a_\Omega \propto$ sum of all stream segment lengths in a order $\Om$ basin
      (assuming uniform drainage density)
    
      So:
      $$ a_\Omega \simeq \sum_{\om=1}^{\Om} n_\om \bar{\okell}_\om/\rhodd $$
      $$
      {
        \propto \sum_{\om=1}^{\Om}
       } 
       {
         \underbrace{R_n^{\ \Om-\om} \cdot \overbrace{1}^{\alert{n_\Omega}}}_{\alert{n_\om}}
       }
       {
         \underbrace{\bar{\okell}_1 \cdot R_\okell^{\ \om-1}}_{\alert{\bar{\okell}_\om}}
       }
       $$
     {
       $$
       = 
       \frac{R_n^{\ \Om}}{R_\okell} \bar{\okell}_1
       \sum_{\om=1}^{\Om} 
       \left(
       \frac{R_\okell}{R_n}
       \right)^\om
       $$
       }
    
  

\begin{frame}[label=]
  \textbf{Reducing Horton's laws:}

  \textbf{Continued ...}
    
    
      $$
      \alert{a_\Om} \propto \frac{R_n^\Om}{R_\okell} \bar{\okell}_1
      \sum_{\om=1}^{\Om} 
       \left(
         \frac{R_\okell}{R_n}
       \right)^\om
      $$
      {
        $$
        =
        \frac{R_n^\Om}{R_\okell}
        \bar{\okell}_1
        \frac{R_\okell}{R_n}
        \frac
        {1-(R_\okell/R_n)^\Om}
        {1-(R_\okell/R_n)}
        $$
      }
      {
        $$
        \sim
        \alert{R_n^{\Om-1}}
        \bar{\okell}_1
        \frac
        {1}
        {1-(R_\okell/R_n)}
        \mbox{\ as $\Om \nearrow$}
        $$
      }
    {
        So, $a_\Om$ is growing like $R_n^{\ \Om}$ and therefore:
        $$
        \alert{\boxed{R_n \equiv R_a}}
        $$
      }
    
  


\begin{frame}[label=]
  \textbf{Reducing Horton's laws:}

  \textbf{Not quite:}
    
     ... But this only a rough argument
      as Horton's laws do not imply a strict hierarchy
     Need to account for sidebranching.
     
      \insertassignmentquestion{02}{2}{5}
    
  


\begin{frame}[label=]
  \textbf{Equipartitioning:}

  \textbf{Intriguing division of area:}
  
  
    Observe: Combined area of basins of order $\om$ 
    independent of $\om$.
  
    Not obvious: basins of low orders not necessarily contained
    in basis on higher orders.
  
    Story: $$ {R_n \equiv R_a} 
    \Rightarrow \boxed{n_\om \bar{a}_\om = \mbox{const}} $$
  
    Reason:
    $$ n_\om \propto (R_n)^{-\om} $$
    $$ \bar{a}_\om \propto (R_a)^{\om} \propto n_\om^{-1}$$
  
  


\begin{frame}[label=]
  \textbf{Equipartitioning:}
  \textbf{Some examples:}
    \begin{center}
      \includegraphics[width=0.4\textwidth]{figequipart_mispi}
      \includegraphics[width=0.4\textwidth]{figequipart_amazon} \\
      \includegraphics[width=0.4\textwidth]{figequipart_nile}
    \end{center}
  



%% \end{comment}

%% \begin{comment}

\section{Scaling\ relations}

\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{The story so far:}
    
     Natural branching networks are \alert{hierarchical},
      \alert{self-similar} structures
     Hierarchy is \alert{mixed}
     Tokunaga's law describes detailed architecture: $T_k = T_1R_T^{k-1}$.
     We have connected Tokunaga's and Horton's laws
     Only two Horton laws are independent ($R_n = R_a$)
     Only \alert{two} parameters are \alert{independent}: $(T_1,R_T) \Leftrightarrow (R_n,R_\okell)$
    
  
  

\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{A little further...}
    
     Ignore stream ordering for the moment
     Pick a random location on a branching network $p$.
     Each point $p$ is associated with a basin and a longest stream length
     \alert{Q:} What is probability that the $p$'s drainage basin
      has area $a$?
      {
        $ \alert{P(a) \propto a^{-\tau}} \mbox{\ \ for large $a$}$
      }
     \alert{Q:} What is probability that the longest stream from
      $p$ has length $\msl$?
      {
        $ \alert{P(\msl) \propto \msl^{-\gamma}} \mbox{\ \ for large $\msl$}$
      }
    
      Roughly observed: $1.3 \lesssim \tau \lesssim 1.5$
      and  $1.7 \lesssim \gamma \lesssim 2.0$
    
  
  

\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Probability distributions with power-law decays}
    
     We see them everywhere:
      
       Earthquake magnitudes (Gutenberg-Richter law)
       City sizes (Zipf's law)
       Word frequency (Zipf's law)\cite{zipf1949a}
       Wealth (maybe not---at least heavy tailed)
       Statistical mechanics (phase transitions)\cite{goldenfeld1992a}
      
     A big part of the story of complex systems
     Arise from \alert{mechanisms}: growth, randomness, optimization, ...
     Our task is always to illuminate the mechanism...
    
  

\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Connecting exponents}
    
     We have the detailed picture of branching networks (Tokunaga and
      Horton)
     Plan: Derive $P(a) \propto a^{-\tau}$ and $P(\msl) \propto \msl^{-\gamma}$
      starting with Tokunaga/Horton story\cite{tarboton1990a,devries1994a,dodds1999a}
     Let's work on $P(\msl)$...
     Our first fudge: assume Horton's laws hold throughout a basin of
      order $\Omega$.
     (We know they deviate from strict laws for low $\om$ and high $\om$
      but not too much.)
     Next: place stick between teeth.  
      {Bite stick.}  
      {Proceed.}  
    
  

\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
     Often useful to work with \alert{cumulative distributions},
      especially when dealing with power-law distributions.
     The complementary cumulative distribution turns out
      to be most useful:
      $$
      P_> (\msl_\ast) = 
      P (\msl > \msl_\ast) =
      \int_{\msl=\msl_{\ast}}^{\msl_{\max}} P(\msl) {\textnormal{d}}{\msl}
      $$
    
      $$
      P_> (\msl_\ast) =  1 - P(\msl < \msl_\ast)
      $$
     Also known as the exceedance probability.
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
      
        The connection between $P(x)$ and $P_>(x)$ 
        when $P(x)$ has a power law tail is simple:
      
        Given $P(\msl) \sim \msl^{-\gamma}$ large $\msl$ then
        for large enough $\msl_\ast$
        $$ 
        P_> (\msl_\ast) = 
        \int_{\msl=\msl_{\ast}}^{\msl_{\max}} P(\msl)\, {\textnormal{d}}{\msl}
        $$
        {
          $$
          \sim
          \int_{\msl=\msl_{\ast}}^{\msl_{\max}} \alert{\msl^{-\gamma}} {\textnormal{d}}{\msl}
          $$
        }
        {
          $$
          = 
          \left.
            \frac{\msl^{-\gamma+1}}
            {-(\gamma-1)}
          \right|_{\msl=\msl_{\ast}}^{\msl_{\max}}
          $$
        }
        {
          $$
          \propto
          \msl_\ast^{\alert{-\gamma+1}}
          \mbox{\quad for $ \msl_{\max} \gg \msl_\ast$}
          $$
        }
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
     \alert{Aim:} determine probability of randomly choosing
      a point on a network with main stream length $> \msl_\ast$
     Assume some spatial sampling resolution $\Delta$
     Landscape is broken up into grid of $\Delta \times \Delta$ sites
     Approximate $P_> (\msl_\ast)$ as 
      $$
      P_> (\msl_\ast)
      =
      \frac
      {N_> (\msl_\ast; \Delta)}
      {N_> (0; \Delta)}.
      $$
      where $N_> (\msl_\ast; \Delta)$ is the number of sites
      with main stream length $> \msl_\ast$.
     Use Horton's law of stream segments: $\bar{\okell}_\om/\bar{\okell}_{\om-1} = R_\okell$...
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
     Set $\msl_\ast = \bar{\msl}_\om$ for some $1 \ll \om \ll \Om$.
    
      $$
      P_> (\bar{\msl}_\om)
      =
      \frac
      {N_> (\bar{\msl}_\om; \Delta)}
      {N_> (0; \Delta)}
      {
        \simeq
        \frac
        {
          \sum_{\om'=\om+1}^{\Om} n_{\om'}
          \bar{\okell}_{\om'}/{\Delta}{\alert{\cancel{\Delta}}}
        }
        {
          \sum_{\om'=1}^{\Om} n_{\om'} \bar{\okell}_{\om'}/{\Delta}{\alert{\cancel{\Delta}}}
        }
      }
      $$
    
      $\Delta$'s cancel
     
      Denominator is $a_\Om \rhodd$, a constant.
    
      So...  {using Horton's laws...}
      $$
      P_> (\bar{\msl}_\om)
      \propto
      \sum_{\om'=\om+1}^{\Om} n_{\om'} \bar{\okell}_{\om'}
      {
        \simeq
        \sum_{\om'=\om+1}^{\Om} 
        {\alert{(1\cdot R_n^{\, \Om-\om'})}}
        {\alert{(\bar{\okell}_{1} \cdot R_\okell^{\, \om'-1})}}
      }
      $$
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
     We are here:
      $$
      P_> (\bar{\msl}_\om)
      \propto
      \sum_{\om'=\om+1}^{\Om} 
      (1 \cdot R_n^{\, \Om-\om'})
      (\bar{\okell}_1 \cdot R_\okell^{\, \om'-1})
      $$
     Cleaning up irrelevant constants:
      $$
      P_> (\bar{\msl}_\om)
      \propto
      \sum_{\om'=\om+1}^{\Om} 
      \left(
        \frac{R_\okell}{R_n}
      \right)^{\om'}
      $$
     Change summation order by substituting $\om'' = \Om - \om'$.
     Sum is now from $\om''=0$ to $\om'' = \Om - \om - 1$
      {(equivalent to $\om' = \Om$ down to $\om' = \om + 1$)}
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
    
      $$
      P_> (\bar{\msl}_\om)
      \propto
      \sum_{\om''=0}^{\Om-\om-1} 
      \left(
        \frac{R_\okell}{R_n}
      \right)^{\Om-\om''}
      {
        \propto
        \sum_{\om''=0}^{\Om-\om-1} 
        \left(
          \frac{R_n}{R_\okell}
        \right)^{\om''}
        }
      $$
     Since $R_n > R_\okell$ and $1 \ll \om \ll \Om$,
      {
        $$
        P_> (\bar{\msl}_\om)
        \propto
        \left(
          \frac{R_n}{R_\okell}
        \right)^{\Om-\om}
        {
          \alert{
            \propto
            \left(
              \frac{R_n}{R_\okell}
            \right)^{-\om}
          }
        }
        $$
        again using $\sum_{i=0}^{n-1} a^{i} = (a^{\, n}-1)/(a-1)$
      }
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
     Nearly there:
      $$
      P_> (\bar{\msl}_\om)
      \propto
      \left(
        \frac{R_n}{R_\okell}
      \right)^{-\om}
      {
        =
        e^{-\om \ln (R_n/R_\okell)}
      }
      $$
     
      Need to express right hand side in terms of $\bar{\msl}_\om$.
     
      Recall that $\bar{\msl}_\om \simeq \bar{\msl}_1 R_\msl^{\, \om-1}$.
    
      $$
      \bar{\msl}_\om \propto R_\msl^{\, \om} = R_\okell^{\, \om} = e^{\, \om\ln{R_\okell}}
      $$
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
     Therefore:
      $$
      P_> (\bar{\msl}_\om)
      \propto
      e^{-\om \ln (R_n/R_\okell)}
      {
        =
        % ^{\bar{\msl}_\om} ? overbrace
        \left(
          \alert{e^{\, \om \ln R_\okell}}
        \right)^{-\ln (R_n/R_\okell)/\ln(R_\okell)}
      }
      $$
      
        $$
        \propto
        \alert{\bar{\msl}_\om}^{\, -\ln(R_n/R_\okell)/\ln R_\okell}
        $$
      
        $$
        =
        \bar{\msl}_\om^{\, -(\ln R_n - \ln R_\okell)/\ln R_\okell}
        $$
      
        $$
        =
        \bar{\msl}_\om^{\, - \alert{\ln R_n/\ln R_\okell} + 1}
        $$
      
        $$
        =
        \bar{\msl}_\om^{\, -\alert{\gamma} + 1}
        $$
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Finding $\gamma$:}
    
     And so we have:
      $$
      \boxed{\alert{\gamma = \ln R_n / \ln R_\okell}}
      $$
     Proceeding in a similar fashion, we can
      show 
      $$
      \boxed{\alert{\tau = 2 - \ln R_\okell / \ln R_n = 2 - 1/\gamma}}
      $$
      \insertassignmentquestion{02}{2}{6}
     Such connections between exponents are 
      called \alertb{scaling relations}
     Let's connect to one last relationship: Hack's law
    
    
  


\begin{frame}[label=]
  \textbf{Scaling laws}

  \textbf{Hack's law:\cite{hack1957a}}
    
     
      $$
      \boxed{\alert{
          \msl \propto a^{h}
        }}
      $$
    
      Typically observed that $0.5 \lesssim h \lesssim 0.7$.
     Use Horton laws to connect $h$ to Horton ratios:
      $$
      \bar{\msl}_\om \propto R_\okell^{\, \om}
      \mbox{\ and \ }
      \bar{a}_\om \propto R_n^{\, \om}
      $$
    
      Observe:
      $$
      \bar{\msl}_{\om} \propto e^{\, \om \ln R_\okell}
      {
        \propto \left(e^{\, \om \ln R_n} \right)^{ \ln R_\okell / \ln R_n}
      }
      $$
      $$
      {
        \propto 
        \left(
          R_n^{\, \om }
        \right)^{\ln R_\okell / \ln R_n}
      }
      {
        \propto
        \bar{a}_\om^{\ \ln R_\okell / \ln R_n}
      }
      {
        \Rightarrow \boxed{\alert{ h = \ln R_\okell / \ln R_n}}
      }
      $$
    
  



\begin{frame}[label=]
  \textbf{Connecting exponents}
  
  \textbf{Only 3 parameters are independent: \\ e.g., take $d$, $R_n$, and $R_\okell$}
    \begin{center}
      \rowcolors[]{1}{blue!20}{blue!10} 
      \begin{tabular}{cl} %\hline
        \tbf{relation:} & \tbf{scaling relation/parameter:\cite{dodds1999a}}  \\
        $\msl \sim L^{{d}}$ & \alert{$d$}  \\
        $T_{k} = T_1 (R_T)^{k-1}$ & $T_1 = \alert{R_n} - \alert{R_\okell} 
        - 2 + 2\alert{R_\okell}/\alert{R_n}$ \\
        &  $R_T  = \alert{R_\okell}$  \\
        $n_{\om}/n_{\om+1} = R_n$ & \alert{$R_n$}  \\
        $\bar{a}_{\om+1}/\bar{a}_{\om} = R_a$ & $R_a = \alert{R_n}$  \\
        $\bar{\msl}_{\om+1}/\bar{\msl}_{\om} = R_{\msl}$ & $ {R_\msl} = \alert{R_\okell}$  \\
        $\msl \sim a^h$ & $h = \log \alert{R_{\okell}}/ \log \alert{R_n}$  \\
        $a \sim L^D$ & $D = d/h$  \\
        $L_\perp \sim L^H$ & $H = d/h - 1$ \\
        $P(a) \sim a^{-\tau}$ & $\tau = 2 - h$  \\
        $P(\msl)\sim \msl^{-\gamma}$ & $\gamma = 1/h$  \\
        $\Lambda \sim a^\beta$ & $\beta = 1 + h$  \\
        $\lambda \sim L^\varphi$ & $\varphi = d$ \\
      \end{tabular}
    \end{center}
  

\begin{frame}[label=]
  \textbf{Scheidegger's model}

  \textbf{Directed random networks\cite{scheidegger1967a,scheidegger1991a}}
    \includegraphics[width=0.8\textwidth]{scheidmodel-tp-2}
    
    
      $$P(\searrow) = P (\swarrow) = 1/2$$
    
      Functional form of all scaling laws exhibited
      but exponents differ from real world\cite{takayasu1988a,takayasu1989a,takayasu1989b}
    
      Useful and interesting test case
    
  

\begin{frame}[label=]
  \textbf{A toy model---Scheidegger's model}
%%  \textbf{Fluctuations in Hack's law}

  \textbf{Random walk basins:}
    
    Boundaries of basins are random walks
    
    \includegraphics[width=0.9\textwidth]{randwalkriver2}
  

\begin{frame}[label=]
  \textbf{Scheidegger's model}
%%  \textbf{Fluctuations in Hack's law}

  \begin{center}
    \includegraphics[width=0.9\textwidth]{randwalkriver_rot}
  \end{center}


\begin{frame}[label=]
  \textbf{Scheidegger's model}

  \textbf{Prob for first return of a random walk in (1+1) dimensions (from CSYS/MATH 300):}
  
    
      $$P(n) \sim \frac{1}{2\sqrt{\pi}}\  n^{-3/2}.$$
      and so $P(\msl) \propto \msl^{-3/2}$.
    
      Typical area for a walk of length $n$ is $\propto n^{3/2}$:
      $$ \msl \propto a^{\, 2/3}.$$
    
      Find $\tau=4/3$, $h=2/3$, $\gamma = 3/2$, $d=1$.
    
      Note $\tau = 2 - h$ and $\gamma = 1/h$.
    
      $R_n$ and $R_\ell$ have not been derived analytically.
    
  

\begin{frame}[label=]
  \textbf{Equipartitioning reexamined:}

  \textbf{Recall this story:}
    \begin{center}
      \includegraphics[width=0.4\textwidth]{figequipart_mispi}
      \includegraphics[width=0.4\textwidth]{figequipart_amazon}\\
      \includegraphics[width=0.4\textwidth]{figequipart_nile}
    \end{center}
  


  \textbf{Equipartitioning}

  
    
    
      What about 
      $$ P(a) \sim a^{-\tau} \qquad ? $$
    
      Since $\tau > 1$, suggests no equipartitioning:
      $$ aP(a) \sim a^{-\tau+1} \neq \mbox{const} $$
    
      $P(a)$ overcounts basins within basins...
    
      while
      stream ordering separates basins...
    
  



\section{Fluctuations}

\begin{frame}[label=]
    \textbf{Fluctuations}

    \textbf{Moving beyond the mean:}
      
       Both Horton's laws and Tokunaga's law
        relate average properties, e.g.,
        $$ \bar{\okell}_\om / \bar{\okell}_{\om-1} = R_\okell$$
       Natural generalization to consider
        relationships between \alert{probability distributions}
       Yields rich and full description of 
        branching network structure
       See into the heart of randomness...
      
    


\begin{frame}[label=]
  \textbf{A toy model---Scheidegger's model}

  \textbf{Directed random networks\cite{scheidegger1967a,scheidegger1991a}}
    \includegraphics[width=0.8\textwidth]{scheidmodel-tp-2}
    
    
      $$P(\searrow) = P (\swarrow) = 1/2$$
    
      Flow is directed downwards
    
  



%% \begin{comment}

\begin{frame}[label=]
  \textbf{Generalizing Horton's laws}

  
  
    $\bar{\msl}_\om \propto (R_\msl)^\omega \alert{\Rightarrow}
    N(\msl|\om) = (R_nR_\msl)^{-\om} F_\msl(\msl / R_\msl^{\om}) $
  
    $\bar{a}_\om \propto (R_a)^\omega \alert{\Rightarrow}
    N(a|\om) = (R_n^2)^{-\om} F_a(a / R_n^{\om}) $
  
      
          
      
      \includegraphics[width=\textwidth]{figlw_collapse_mispi2}
        
           
      
      \includegraphics[width=\textwidth]{figlw_collapse_mispi2a}
      
  
   Scaling collapse works well for intermediate orders
   All \alert{moments} grow exponentially with order
  
  

\begin{frame}[label=]
  \textbf{Generalizing Horton's laws}

  
   How well does overall basin fit internal pattern?
  
      
    \includegraphics[width=\textwidth]{figlw_blownup}    
    
    
    
      Actual length = \alert{4920 km} (at 1 km res)
    
      Predicted Mean length = \alert{11100 km}
    
      Predicted Std dev = \alert{5600 km}
    
      Actual length/Mean length = \alert{44 \%}
    
      Okay.
    
  

\begin{frame}[label=]
  \textbf{Generalizing Horton's laws}

  Comparison of predicted versus measured main stream lengths
  for large scale river networks (in $10^3$ km):
  \begin{center}
    \rowcolors[]{1}{blue!20}{blue!10} 
    \begin{tabular}{lccccc}
      \hline
      basin: &  $\msl_\Om$ & $\bar{\msl}_\Omega$ & 
      $\sigma_\msl$ & $\msl_\Om/\bar{\msl}_\Omega$ & $\sigma_\msl/\bar{\msl}_\Omega$ \\ \hline
      Mississippi & 4.92 & 11.10 & 5.60 & 0.44 & 0.51 \\
      Amazon &  5.75 & 9.18 & 6.85 & 0.63 & 0.75 \\
      Nile & 6.49 & 2.66 & 2.20 & 2.44 & 0.83 \\
      Congo & 5.07 & 10.13 & 5.75 & 0.50 & 0.57 \\ 
      Kansas & 1.07 & 2.37 & 1.74 & 0.45 & 0.73 \\ \hline\hline
      & $a_\Om$ & $\bar{a}_\Omega$ & $\sigma_a$ & $a_\Om/\bar{a}_\Omega$ & $\sigma_a/\bar{a}_\Omega$ \\ \hline
      Mississippi & 2.74 & 7.55 & 5.58 & 0.36 & 0.74 \\
      Amazon & 5.40 & 9.07 & 8.04 & 0.60 & 0.89 \\
      Nile & 3.08 & 0.96 & 0.79 & 3.19 & 0.82 \\
      Congo & 3.70 & 10.09 & 8.28 & 0.37 & 0.82 \\
      Kansas & 0.14 & 0.49 & 0.42 & 0.28 & 0.86 \\
    \end{tabular}
  \end{center}



%% \begin{frame}[label=]
%%   \textbf{Generalizing Horton's laws}
%% 
%%   \begin{center}
%%     \includegraphics[angle=90,width=.7\textwidth]{figlw_collapse_mispi}    
%%   \end{center}
%% 
%% 
\begin{frame}[label=]
  \textbf{Combining stream segments distributions:}

      
    \includegraphics[width=\textwidth]{network1}
    
    
     Stream segments sum to give main stream lengths
     $$ \msl_\om = \sum_{\mu=1}^{\mu=\om} \okellsnum{\mu} $$
     $P(\msl_\om)$ is a convolution of distributions
      for the $\okell_\om$
    
    
  



\begin{frame}[label=]
  \textbf{Generalizing Horton's laws}

  
   Sum of variables 
  $ \msl_\om = \sum_{\mu=1}^{\mu=\om} \okellsnum{\mu} $
  leads to convolution of distributions:
  $$N(\msl|\om) = N(\okell|1) \ast N(\okell|2) \ast\cdots\ast N(\okell|\om)$$
  
  {
          
                                %    \includegraphics[angle=90,width=\textwidth]{figellw_collapse_mispi2b}
      \includegraphics[width=\textwidth]{figellw_collapse_mispi2a}
      
      $$N(\okell|\om) = \frac{1}{R_n^{\om}R_\msl^{\om}}
      F\left(  \okell / R_\msl^\om  \right) $$
      $$ F(x) = e^{-x/\xi} $$
      Mississippi: $\xi \simeq 900$ m.
      }



\begin{frame}[label=]
  \textbf{Generalizing Horton's laws}

  
   Next level up: Main stream length distributions must
    combine to give overall distribution for stream length
  
      
    \includegraphics[width=\textwidth]{figlw_powerlawsum_mispi}    
    
    
     
      $ P(\msl) \sim \msl^{-\gamma} $ 
     
      Another round of convolutions\cite{dodds2001b}
     
      Interesting...
    

    
%%  check this 
%%  and $ P(\msl_\omega) \sim \msl_\omega^{-1-\gamma}$



%% \begin{frame}[label=]
%%   \textbf{Generalizing Horton's laws}
%% 
%%   \begin{center}
%%     \includegraphics[width=0.6\textwidth]{figmoments_l_mispi_noname}
%%   \end{center}
%% 
\begin{frame}[label=]
  \textbf{Generalizing Horton's laws}

      
    
     
      Number and area distributions for the Scheidegger model\cite{dodds2001b}
     
      $P(n_{1,6})$ versus $P(a_{\, 6})$
      for a randomly selected $\om=6$ basin.
    
    
    \includegraphics[width=\textwidth]{figsche_number_area2_noname}
  



\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}
  
  Scheidegger:\\
  \includegraphics[width=.48\textwidth]{figsche_Tok_omega_uncollapse_noname}
  \includegraphics[width=.48\textwidth]{figsche_Tok_omega_collapse_noname} 

  
   Observe exponential distributions for $T_{\mu,\nu}$
   Scaling collapse works using $R_\okell$
  


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}
  
  Mississippi:\\
  \includegraphics[width=.48\textwidth]{figtokdist_order1_b_noname} 
  \includegraphics[width=.48\textwidth]{figtokdist_order1_collapse_b_noname}

  
   Same data collapse for Mississippi...
  


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  So
  \[
  P(\Tmunu) = (R_\okell)^{\mu-\nu-1}
  P_t\left[ \Tmunu / (R_\okell)^{\mu-\nu-1}  \right]
  \]
  where
  \[
  P_t(z) = \frac{1}{\xi_t} e^{-z/\xi_t}.
  \]

  \[ \boxed{P(\okellsnum{\mu}) \Leftrightarrow P(\Tmunu)} \]

  
   Exponentials arise from randomness.
   Look at joint probability $P(\okellsnum{\mu},\Tmunu)$.
  


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  \textbf{Network architecture:}
          
      
       
        Inter-tributary lengths exponentially distributed
       
        Leads to random spatial distribution of stream segments
      
      
      \includegraphics[width=\textwidth]{tokfluct}
      


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  
  
    Follow streams segments down stream from their beginning
  
    Probability (or rate) of an order $\mu$ stream segment terminating is \alert{constant}:
    $$
    \tilde{p}_{\mu} \simeq 1/(R_\okell)^{\mu-1}\xi_\okell 
    $$
   
    Probability decays exponentially with stream order
  
    Inter-tributary lengths exponentially distributed
  
    $\Rightarrow$ random spatial distribution of stream segments
  

\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  
   Joint distribution for generalized version
    of Tokunaga's law:
    $$
    P(\okellsnum{\mu},\Tmunu) = \tilde{p}_{\mu}
    \binom{\okellsnum{\mu} - 1}{\Tmunu}
    p_{\nu}^{\Tmunu}
    ( 1 - p_\nu - \tilde{p}_{\mu})^{\okellsnum{\mu} - \Tmunu - 1}
    $$
    where 
    
     $p_\nu = $ probability of absorbing an order $\nu$ side stream
     $\tilde{p}_{\mu} = $ probability of an order $\mu$ stream terminating 
    
   Approximation: depends on distance units of $s_\mu$
   In each unit of distance along stream, there is 
    one chance of a side stream entering or the stream terminating.
  


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  
   
    Now deal with this thing:
    $$
    P(\okellsnum{\mu},\Tmunu) = \tilde{p}_{\mu}
    \binom{\okellsnum{\mu} - 1}{\Tmunu}
    p_{\nu}^{\Tmunu}
    ( 1 - p_\nu - \tilde{p}_{\mu})^{\okellsnum{\mu} - \Tmunu - 1}
    $$
  
    Set $(x,y) = (\okellsnum{\mu}, \Tmunu)$ and $q = 1 - p_\nu - \tilde{p}_{\mu}$,
    approximate liberally.
  
    Obtain
    $$
    P(x,y) = N x^{-1/2} \left[ F(y/x) \right]^{x}
    $$
    where
    $$
    F(v) = \rbfrac{1-v}{q}^{-(1-v)} \rbfrac{v}{p}^{-v}.
    $$
  


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  
   Checking form of $P(\okellsnum{\mu},\Tmunu)$ works:
  

  Scheidegger:

    \includegraphics[width=0.48\textwidth]{figsche_Tell_f_theory_noname}
    \includegraphics[width=0.48\textwidth]{figsche_Tell_f_theory2_noname}


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  
   Checking form of $P(\okellsnum{\mu},\Tmunu)$ works:
  

  Scheidegger:
  
    \includegraphics[width=0.48\textwidth]{figsche_Tell_theory_noname}
    \includegraphics[width=0.48\textwidth]{figsche_ellT_theory_noname} 


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  
   Checking form of $P(\okellsnum{\mu},\Tmunu)$ works:
  

  Scheidegger:

      \includegraphics[width=0.48\textwidth]{figsche_Tell_otrib_uncollapse_noname}
      \includegraphics[width=0.48\textwidth]{figsche_Tell_otrib_collapse_noname}


\begin{frame}[label=]
  \textbf{Generalizing Tokunaga's law}

  
   Checking form of $P(\okellsnum{\mu},\Tmunu)$ works:
  

  Mississippi:
  
      \includegraphics[width=0.48\textwidth]{figtokdistdata_mispi10_3_noname}
      \includegraphics[width=0.48\textwidth]{figtokdistdata_mispi10_3coll_noname}




\section{Models}

\begin{frame}[label=]
  \textbf{Models}

  \textbf{Random subnetworks on a Bethe lattice\cite{shreve1967a}}
          
      \includegraphics[width=\textwidth]{shreve}
      
      
       Dominant theoretical concept for several decades.
       Bethe lattices are fun and tractable.
       Led to idea of ``Statistical inevitability'' of river network statistics\cite{kirchner1993a}
       But Bethe lattices unconnected with surfaces.
       In fact, Bethe lattices $\simeq$ infinite dimensional spaces (oops).
       So let's move on...
      
      


\begin{frame}[label=]
  \textbf{Scheidegger's model}

  \textbf{Directed random networks\cite{scheidegger1967a,scheidegger1991a}}
    \includegraphics[width=0.8\textwidth]{scheidmodel-tp-2}
    
    
      $$P(\searrow) = P (\swarrow) = 1/2$$
    
      Functional form of all scaling laws exhibited
      but exponents differ from real world\cite{takayasu1988a,takayasu1989a,takayasu1989b}
    
  



\begin{frame}[label=]
  \textbf{Optimal channel networks}

  \textbf{Rodr\'iguez-Iturbe, Rinaldo, et al.\cite{rodriguez-iturbe1997a}}
    
     
      Landscapes $h(\vec{x})$ evolve such that
      energy dissipation $\dot{\varepsilon}$ is minimized, where 
      $$
      {
      \dot{\varepsilon} 
        \propto \int \mbox{d}\vec{r} \; (\mbox{flux}) \times (\mbox{force}) 
      }
      {
        \sim  \sum_i a_i \nabla h_i 
      }
      {
        \sim  \sum_i a_i^\gamma 
      }
      $$
    
      Landscapes obtained numerically give exponents near that of real networks.
    
      \alert{But:}
      numerical method used matters.
    
      \alert{And:}
      Maritan et al.\ find basic universality
      classes are that of Scheidegger, self-similar,
      and a third kind of random network\cite{maritan1996b}
    
  
  

\begin{frame}[label=]
  \textbf{Theoretical networks}

  \textbf{Summary of universality classes:}
    \begin{center}
      \rowcolors[]{1}{blue!20}{blue!10} 
      \begin{tabular}{ccc}
        \hline\hline
        \textbf{network} & h & d \\
        \hline
        Non-convergent flow      & 1     & 1 \\
        Directed random          & 2/3   & 1 \\
        Undirected random        & 5/8 & 5/4 \\
        Self-similar             & 1/2 & 1 \\
        OCN's (I)                & 1/2 & 1 \\
        OCN's (II)               & 2/3 & 1 \\
        OCN's (III)              & 3/5 & 1 \\
        Real rivers              & 0.5--0.7 & 1.0--1.2 \\
        \hline\hline
      \end{tabular}

      $ h \Rightarrow \msl \propto a^h$ (Hack's law).

      $ d \Rightarrow \msl \propto L_\parallel^d$ (stream self-affinity).

    \end{center}
  




%% \begin{frame}[label=]
%%   \textbf{Summary}
%% 
%%   
%%    Generalized Horton and Tokunaga imply randomness in spatial structure.
%%    Fluctuations on order of system size.
%%    Strong deviations from Hack's law at large and small scales for basins of all sizes.
%%    Large scale deviations may persist over 1 to 2 orders of magnitude
%%   in area.
%%    Increased resolution will not help.
%%    Intermediate scaling is approximate.
%%    Universality classes indeterminate.
%%    Fluctuations may be used to distinguish networks.
%%    Unlikely structures suggest geology is at work.
%%   
%% 
%% 


\section{Nutshell}

\begin{frame}[label=]
  \textbf{Nutshell}

  \textbf{Branching networks II Key Points:}
    
    
      Horton's laws and Tokunaga law all fit together.
    
      For 2-d networks, these laws are `planform' laws and ignore slope.
    
      Abundant scaling relations can be derived.
    
      Can take $R_n$, $R_\ell$, and $d$ as three independent parameters
      necessary to describe all 2-d branching networks.
    
      For scaling laws, only $h = \ln R_\ell/ \ln R_n$ and $d$ are needed.
    
      Laws can be extended nicely to laws of distributions.
    
      Numerous models of branching network evolution exist: nothing rock solid yet.
    
    
  




%%%%%%%%%%%%%%%%%%%%%%%%
%% to do (maybe)

%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}

\section{Cardiovascular\ networks}

%% kassab's paper?
%% too much!

\begin{comment}

%% outtakes

\begin{frame}[label=]
  

  \textsl{Menu:}\\

  $\bullet$ Some simple models and theories.

  $\bullet$ Unification of scaling laws.

  $\bullet$ Fluctuations about Hack's law.

  $\bullet$ Deviations I: Hack's law at small scales.

  $\bullet$ Deviations II: Hack's law at intermediate scales.

  $\bullet$ Network componentry\\
  (generalization of Horton's laws).

  $\bullet$ Network architecture\\
  (generalization of Tokunaga's law).

  $\bullet$ Deviations III: Hack's law at large scales.

  $\bullet$ Run out of steam.


\begin{frame}[label=]
  

\textsl{Tokunaga's law:}

\parbox{.48\textwidth}{
Average number of streams of order $\nu$
that enter as tributaries to 
streams of order $\mu$:
\[ \Tmunu \]
\vspace{5mm}

Self-similarity:
\[
\Tmunu = T_{\mu-\nu} = T_{k}.
\]
\vspace{5mm}

Tokunaga's law:
\[
T_{k} = T_1 (R_\okell)^{k-1}.
\]
}
\parbox{.48\textwidth}{
  \begin{center}
    \includegraphics[width=.0435\textwidth]{network3}

    \includegraphics[width=.27\textwidth]{network2}

    \includegraphics[width=.3435\textwidth]{network1}
  \end{center}
}

  
\end{comment}
